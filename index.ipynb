{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423ff01c-485d-4a09-bf75-1676822ade8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# This is the API Gateway endpoint \n",
    "API_ENDPOINT = \"https://s35t79fgcl.execute-api.ap-south-1.amazonaws.com/dev/upload-url\"\n",
    "# ---\n",
    "\n",
    "def get_upload_url(filename):\n",
    "    \"\"\"\n",
    "    Calls Lambda API to get a presigned S3 URL.\n",
    "    \"\"\"\n",
    "    print(f\"1. Requesting upload URL for: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # We send the filename in the body, as the Lambda code expects.\n",
    "        response = requests.post(API_ENDPOINT, json={'filename': filename})\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"   ‚ùå Error: Failed to get URL (Status {response.status_code})\")\n",
    "            print(f\"   Response: {response.text}\")\n",
    "            return None, None\n",
    "\n",
    "        # API Gateway proxy integration returns a JSON string in the 'body' key\n",
    "        try:\n",
    "            data = json.loads(response.json().get('body', response.text))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"   ‚ùå Error: Could not decode JSON response: {response.text}\")\n",
    "            return None, None\n",
    "            \n",
    "        upload_url = data.get('upload_url')\n",
    "        doc_id = data.get('document_id')\n",
    "        \n",
    "        if not upload_url or not doc_id:\n",
    "            print(f\"   ‚ùå Error: Incomplete response from Lambda.\")\n",
    "            print(f\"   Lambda Response: {data}\")\n",
    "            return None, None\n",
    "\n",
    "        print(f\"   ‚úÖ Success. Document ID: {doc_id}\")\n",
    "        return upload_url, doc_id\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   ‚ùå NETWORK ERROR: Could not connect to your API Gateway.\")\n",
    "        print(f\"   Check that the API_ENDPOINT is correct and deployed.\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def upload_file_to_s3(upload_url, file_path):\n",
    "    \"\"\"\n",
    "    Uploads the actual file to the presigned URL.\n",
    "    (Renamed from 'upload_file' to avoid name conflict)\n",
    "    \"\"\"\n",
    "    print(f\"\\n2. Uploading {os.path.basename(file_path)} to S3...\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            file_data = f.read()\n",
    "        \n",
    "        # Make the PUT request with the raw file data\n",
    "        response = requests.put(upload_url, data=file_data)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(f\"   ‚úÖ SUCCESS! File upload complete.\")\n",
    "            return True\n",
    "        else:\n",
    "            # This will show the <Error> XML from S3 if it fails\n",
    "            print(f\"   ‚ùå UPLOAD FAILED (Status {response.status_code})\")\n",
    "            print(f\"   Response from S3: {response.text}\")\n",
    "            return False\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   ‚ùå NETWORK ERROR during upload. This could be a firewall.\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ‚ùå Error: Local file not found at {file_path}\")\n",
    "        return False\n",
    "\n",
    "def upload_document(file_path):\n",
    "    \"\"\"\n",
    "    Main function to run the complete upload process from a Jupyter cell.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The local path to the file you want to upload.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Check Config ---\n",
    "    if \"YOUR-API-ID\" in API_ENDPOINT:\n",
    "        print(\"=\"*50)\n",
    "        print(\"‚ùå ERROR: Please edit the script (line 7)\")\n",
    "        print(\"   You must set your `API_ENDPOINT` variable.\")\n",
    "        print(\"=\"*50)\n",
    "        return\n",
    "\n",
    "    # --- Check File Path ---\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå Error: File not found at {file_path}\")\n",
    "        return\n",
    "        \n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # --- Run Process ---\n",
    "    print(\"=\"*50)\n",
    "    upload_url, doc_id = get_upload_url(filename)\n",
    "    \n",
    "    if upload_url and doc_id:\n",
    "        success = upload_file_to_s3(upload_url, file_path)\n",
    "        if success:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"üéâ Process Complete!\")\n",
    "            print(f\"   Document ID: {doc_id}\")\n",
    "            print(f\"   File: {filename}\")\n",
    "            print(\"\\n   The 'process-document' Lambda should now be triggered.\")\n",
    "            print(\"=\"*50)\n",
    "            return doc_id # Return the doc_id for use in other cells\n",
    "        else:\n",
    "            print(\"\\nUpload failed. Please check errors above.\")\n",
    "    else:\n",
    "        print(\"\\nCould not get upload URL. Aborting.\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a397068a-35de-4968-b814-a6bc23dcd9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. Requesting upload URL for: 1.pdf\n",
      "   ‚úÖ Success. Document ID: 6d368fba\n",
      "\n",
      "2. Uploading 1.pdf to S3...\n",
      "   ‚úÖ SUCCESS! File upload complete.\n",
      "\n",
      "==================================================\n",
      "üéâ Process Complete!\n",
      "   Document ID: 6d368fba\n",
      "   File: 1.pdf\n",
      "\n",
      "   The 'process-document' Lambda should now be triggered.\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6d368fba'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_document(\"1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867cbc62-3b95-479e-b3bf-3155cbb6f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAG Pipeline Test\n",
      "Question: What methodology was used in this study?\n",
      "Document ID: 6d368fba\n",
      "============================================================\n",
      "\n",
      "1. Calling /query endpoint to find relevant chunks...\n",
      "‚ùå Error during /query step: 'body'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "API_BASE_URL = \"https://s35t79fgcl.execute-api.ap-south-1.amazonaws.com\" \n",
    "\n",
    "QUERY_ENDPOINT = f\"{API_BASE_URL}/dev/query\"\n",
    "ANSWER_ENDPOINT = f\"{API_BASE_URL}/dev/answer\"\n",
    "\n",
    "def test_full_rag_pipeline(question, doc_id=None):\n",
    "    \"\"\"\n",
    "    Calls /query to get chunks, then /answer to get a final response.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The user's question.\n",
    "        doc_id (str, optional): The specific document to search in. \n",
    "                                If None, searches all documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"RAG Pipeline Test\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Document ID: {doc_id or 'All Documents'}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # --- STEP 1: RETRIEVAL (/query) ---\n",
    "    print(\"\\n1. Calling /query endpoint to find relevant chunks...\")\n",
    "    query_payload = {\n",
    "        \"question\": question,\n",
    "        \"document_id\": doc_id,\n",
    "        \"top_k\": 3 # Request top 3 chunks\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response_query = requests.post(QUERY_ENDPOINT, json=query_payload)\n",
    "        \n",
    "        if response_query.status_code != 200:\n",
    "            print(f\"‚ùå /query FAILED (Status {response_query.status_code})\")\n",
    "            print(f\"   Response: {response_query.text}\")\n",
    "            return\n",
    "\n",
    "        # Load the body from the Lambda's response\n",
    "        query_data = json.loads(response_query.json()['body'])\n",
    "        top_chunks = query_data.get('top_chunks', [])\n",
    "        \n",
    "        if not top_chunks:\n",
    "            print(\"‚ùå /query SUCCEEDED, but no relevant chunks were found.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"‚úÖ /query Success. Found {len(top_chunks)} relevant chunks.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during /query step: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- STEP 2: AUGMENTED GENERATION (/answer) ---\n",
    "    print(\"\\n2. Calling /answer endpoint to generate a final answer...\")\n",
    "    answer_payload = {\n",
    "        \"question\": question,\n",
    "        \"top_chunks\": top_chunks # Pass the chunks we just found\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response_answer = requests.post(ANSWER_ENDPOINT, json=answer_payload)\n",
    "        \n",
    "        if response_answer.status_code != 200:\n",
    "            print(f\"‚ùå /answer FAILED (Status {response_answer.status_code})\")\n",
    "            print(f\"   Response: {response_answer.text}\")\n",
    "            return\n",
    "            \n",
    "        # Load the body from the Lambda's response\n",
    "        answer_data = json.loads(response_answer.json()['body'])\n",
    "        final_answer = answer_data.get('answer', 'No answer found.')\n",
    "        sources = answer_data.get('sources', [])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéâ RAG PIPELINE SUCCEEDED!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\nFINAL ANSWER:\\n\")\n",
    "        print(final_answer)\n",
    "        \n",
    "        print(\"\\n\\nSOURCES USED:\\n\")\n",
    "        for i, source in enumerate(sources, 1):\n",
    "            print(f\"  {i}. {source['filename']} (Index: {source['chunk_index']}, Score: {source['similarity_score']})\")\n",
    "            print(f\"     Excerpt: \\\"{source['excerpt']}\\\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during /answer step: {e}\")\n",
    "        return\n",
    "\n",
    "# --- RUN THE TEST ---\n",
    "# ‚¨áÔ∏è This is the document_id from your successful 'handle-query' test ‚¨áÔ∏è\n",
    "MY_DOCUMENT_ID = \"6d368fba\" \n",
    "MY_QUESTION = \"What methodology was used in this study?\"\n",
    "\n",
    "test_full_rag_pipeline(MY_QUESTION, MY_DOCUMENT_ID)\n",
    "\n",
    "# --- TEST 2: Ask a question to ALL documents (if you have more than one) ---\n",
    "# test_full_rag_pipeline(\"What is the main conclusion about large language models?\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085c148-766a-4379-9084-a61ea20554d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
